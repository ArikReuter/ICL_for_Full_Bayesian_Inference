{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arik_\\Documents\\Dokumente\\Job_Clausthal\\PFNs\\Repository\\PFNExperiments\\.conda\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy 0.9787234042553191\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tabpfn import TabPFNClassifier\n",
    "\n",
    "X, y = load_breast_cancer(return_X_y=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "# N_ensemble_configurations controls the number of model predictions that are ensembled with feature and class rotations (See our work for details).\n",
    "# When N_ensemble_configurations > #features * #classes, no further averaging is applied.\n",
    "\n",
    "classifier = TabPFNClassifier(device='cpu', N_ensemble_configurations=1)\n",
    "\n",
    "classifier.fit(X_train, y_train)\n",
    "y_eval, p_eval = classifier.predict(X_test, return_winning_probability=True)\n",
    "\n",
    "print('Accuracy', accuracy_score(y_test, y_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tabpfn.transformer.TransformerModel"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(classifier.model[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32, device=device)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32, device=device)\n",
    "y_train = torch.tensor(y_train, dtype=torch.int64, device=device)\n",
    "y_test = torch.tensor(y_test, dtype=torch.int64, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate train and test data\n",
    "\n",
    "X_full = torch.cat((X_train, X_test), dim=0).float().unsqueeze(1).to(device)\n",
    "\n",
    "y_full = np.concatenate([y_train, np.zeros(shape=X.shape[0])], axis=0)   # for the test data, we don't have the labels, thus we use zeros\n",
    "y_full = torch.tensor(y_full, device=device).float().unsqueeze(1)   \n",
    "\n",
    "eval_pos = X_train.shape[0]  # position where the test data starts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.scripts.transformer_prediction_interface import transformer_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = classifier.model[2]  # extract the pytorch model from the TabPFNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_from_config(c):\n",
    "    return {'max_features': c['num_features']\n",
    "        , 'rescale_features': c[\"normalize_by_used_features\"]\n",
    "        , 'normalize_to_ranking': c[\"normalize_to_ranking\"]\n",
    "        , 'normalize_with_sqrt': c.get(\"normalize_with_sqrt\", False)\n",
    "            }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\arik_\\Documents\\Dokumente\\Job_Clausthal\\PFNs\\Repository\\PFNExperiments\\.conda\\lib\\site-packages\\torch\\utils\\checkpoint.py:460: UserWarning: torch.utils.checkpoint: please pass in use_reentrant=True or use_reentrant=False explicitly. The default value of use_reentrant will be updated to be False in the future. To maintain current behavior, pass use_reentrant=True. It is recommended that you use use_reentrant=False. Refer to docs for more details on the differences between the two variants.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "pred = transformer_predict(classifier.model[2], X_full, y_full, eval_pos,\n",
    "                                         device=classifier.device,\n",
    "                                         style=classifier.style,\n",
    "                                         inference_mode=False,\n",
    "                                         preprocess_transform='none' if classifier.no_preprocess_mode else 'mix',\n",
    "                                         normalize_with_test=False,\n",
    "                                         N_ensemble_configurations=classifier.N_ensemble_configurations,\n",
    "                                         softmax_temperature=classifier.temperature,\n",
    "                                         multiclass_decoder=classifier.multiclass_decoder,\n",
    "                                         feature_shift_decoder=classifier.feature_shift_decoder,\n",
    "                                         differentiable_hps_as_style=classifier.differentiable_hps_as_style,\n",
    "                                         seed=classifier.seed,\n",
    "                                         return_logits=False,\n",
    "                                         no_grad=False,\n",
    "                                         batch_size_inference=classifier.batch_size_inference,\n",
    "                                         **get_params_from_config(classifier.c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label = torch.argmax(pred, dim=2).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "         1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "         1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "         0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "         1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1,\n",
       "         0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
       "         1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tabpfn.utils import normalize_data, to_ranking_low_mem, remove_outliers\n",
    "from tabpfn.utils import NOP, normalize_by_used_features_f\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import PowerTransformer, QuantileTransformer, RobustScaler\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_input(eval_xs, \n",
    "                     eval_ys,\n",
    "                     preprocess_transform,\n",
    "                     eval_position,\n",
    "                     max_features,\n",
    "                     normalize_with_test = False,\n",
    "                     normalize_to_ranking = False,\n",
    "                     normalize_with_sqrt = False,\n",
    "                     device = torch.device('cpu') if not torch.cuda.is_available() else torch.device('cuda'),\n",
    "                     categorical_feats = []):\n",
    "        \n",
    "        \"\"\"\n",
    "        Preprocess the input data for the transformer model\n",
    "        Args:\n",
    "            eval_xs: torch.Tensor, x-value input for evaluation\n",
    "            eval_ys: torch.Tensor, ys input\n",
    "            preprocess_transform: str, type of preprocessing to be applied. Options: 'none', 'power', 'quantile', 'robust', 'power_all', 'quantile_all', 'robust_all'\n",
    "            eval_position: int, position where the evaluation data starts\n",
    "            max_features: int, maximum number of features to be used\n",
    "            normalize_with_test: bool, whether to normalize with test data\n",
    "            normalize_to_ranking: bool, whether to normalize to ranking\n",
    "            normalize_with_sqrt: bool, whether to normalize with sqrt\n",
    "            device: str, device to be used\n",
    "            categorical_feats: list, list of categorical features\n",
    "        \"\"\"\n",
    "\n",
    "        if eval_xs.shape[1] > 1:\n",
    "            raise Exception(\"Transforms only allow one batch dim - TODO\")\n",
    "\n",
    "        if eval_xs.shape[2] > max_features:\n",
    "            eval_xs = eval_xs[:, :, sorted(np.random.choice(eval_xs.shape[2], max_features, replace=False))]\n",
    "\n",
    "        if preprocess_transform != 'none':\n",
    "            if preprocess_transform == 'power' or preprocess_transform == 'power_all':\n",
    "                pt = PowerTransformer(standardize=True)\n",
    "            elif preprocess_transform == 'quantile' or preprocess_transform == 'quantile_all':\n",
    "                pt = QuantileTransformer(output_distribution='normal')\n",
    "            elif preprocess_transform == 'robust' or preprocess_transform == 'robust_all':\n",
    "                pt = RobustScaler(unit_variance=True)\n",
    "\n",
    "        # eval_xs, eval_ys = normalize_data(eval_xs), normalize_data(eval_ys)\n",
    "        eval_xs = normalize_data(eval_xs, normalize_positions=-1 if normalize_with_test else eval_position)\n",
    "\n",
    "        # Removing empty features\n",
    "        eval_xs = eval_xs[:, 0, :]\n",
    "        sel = [len(torch.unique(eval_xs[0:eval_ys.shape[0], col])) > 1 for col in range(eval_xs.shape[1])]\n",
    "        eval_xs = eval_xs[:, sel]\n",
    "\n",
    "        warnings.simplefilter('error')\n",
    "        if preprocess_transform != 'none':\n",
    "            eval_xs = eval_xs.cpu().numpy()\n",
    "            feats = set(range(eval_xs.shape[1])) if 'all' in preprocess_transform else set(\n",
    "                range(eval_xs.shape[1])) - set(categorical_feats)\n",
    "            for col in feats:\n",
    "                try:\n",
    "                    pt.fit(eval_xs[0:eval_position, col:col + 1])\n",
    "                    trans = pt.transform(eval_xs[:, col:col + 1])\n",
    "                    # print(scipy.stats.spearmanr(trans[~np.isnan(eval_xs[:, col:col+1])], eval_xs[:, col:col+1][~np.isnan(eval_xs[:, col:col+1])]))\n",
    "                    eval_xs[:, col:col + 1] = trans\n",
    "                except:\n",
    "                    pass\n",
    "            eval_xs = torch.tensor(eval_xs).float()\n",
    "        warnings.simplefilter('default')\n",
    "\n",
    "        eval_xs = eval_xs.unsqueeze(1)\n",
    "\n",
    "        # TODO: Caution there is information leakage when to_ranking is used, we should not use it\n",
    "        eval_xs = remove_outliers(eval_xs, normalize_positions=-1 if normalize_with_test else eval_position) \\\n",
    "                if not normalize_to_ranking else normalize_data(to_ranking_low_mem(eval_xs))\n",
    "        # Rescale X\n",
    "        eval_xs = normalize_by_used_features_f(eval_xs, eval_xs.shape[-1], max_features,\n",
    "                                               normalize_with_sqrt=normalize_with_sqrt)\n",
    "\n",
    "        return eval_xs.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(eval_xs, eval_ys, softmax_temperature, return_logits, eval_position, model, num_classes):\n",
    "\n",
    "        output = model(\n",
    "                    (None, eval_xs, eval_ys.float()),\n",
    "                    single_eval_pos=eval_position)[:, :, 0:num_classes]\n",
    "        \n",
    "\n",
    "        output = output[:, :, 0:num_classes] / torch.exp(softmax_temperature)\n",
    "\n",
    "        if not return_logits:\n",
    "                output = torch.nn.functional.softmax(output, dim=-1)\n",
    "\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import random\n",
    "\n",
    "def transformer_predict_custom(\n",
    "                            model, \n",
    "                            eval_xs, \n",
    "                            eval_ys, \n",
    "                            eval_position,\n",
    "                            device='cpu',\n",
    "                            max_features=100,\n",
    "                            style=None,\n",
    "                            num_classes=2,\n",
    "                            extend_features=True,\n",
    "                            normalize_with_test=False,\n",
    "                            normalize_to_ranking=False,\n",
    "                            softmax_temperature=0.0,\n",
    "                            preprocess_transform='mix',\n",
    "                            categorical_feats=[],\n",
    "                            batch_size_inference=16,\n",
    "                            normalize_with_sqrt=False,\n",
    "                            seed=0,\n",
    "                            return_logits=False):\n",
    "    \n",
    "    num_classes = len(torch.unique(eval_ys))\n",
    "\n",
    "\n",
    "    eval_xs, eval_ys = eval_xs.to(device), eval_ys.to(device)\n",
    "    eval_ys = eval_ys[:eval_position]\n",
    "\n",
    "    model.to(device)\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    style = None\n",
    "    softmax_temperature = torch.log(torch.tensor([0.8]))\n",
    "    softmax_temperature = torch.tensor(softmax_temperature).to(device)\n",
    "\n",
    "    inputs, labels = [], []\n",
    "\n",
    "    eval_xs_, eval_ys_ = eval_xs.clone(), eval_ys.clone()\n",
    "\n",
    "\n",
    "    eval_xs_ = preprocess_input(\n",
    "        eval_xs=eval_xs_,\n",
    "        eval_ys=eval_ys_,\n",
    "        preprocess_transform=preprocess_transform,\n",
    "        eval_position=eval_position,\n",
    "        max_features=max_features,\n",
    "        normalize_with_test=normalize_with_test,\n",
    "        normalize_to_ranking=normalize_to_ranking,\n",
    "        normalize_with_sqrt=normalize_with_sqrt,\n",
    "        device=device,\n",
    "        categorical_feats=categorical_feats\n",
    "    )\n",
    "\n",
    "    eval_ys_ = ((eval_ys_ + 0) % num_classes).float()\n",
    "\n",
    "    print(eval_xs_.shape, eval_ys_.shape)\n",
    "\n",
    "    eval_xs_ = torch.cat([eval_xs_[..., 0:],eval_xs_[..., :0]],dim=-1) # this shifts the features by one\n",
    "\n",
    "    print(eval_xs_.shape, eval_ys_.shape)\n",
    "\n",
    "    # Extend X\n",
    "    if extend_features:\n",
    "        eval_xs_ = torch.cat(\n",
    "            [eval_xs_,\n",
    "                torch.zeros((eval_xs_.shape[0], eval_xs_.shape[1], max_features - eval_xs_.shape[2])).to(device)], -1)\n",
    "    inputs += [eval_xs_]\n",
    "    labels += [eval_ys_]\n",
    "\n",
    "    inputs = torch.cat(inputs, 1)\n",
    "    inputs = torch.split(inputs, batch_size_inference, dim=1)\n",
    "    labels = torch.cat(labels, 1)\n",
    "    labels = torch.split(labels, batch_size_inference, dim=1)\n",
    "\n",
    "    print(inputs[0].shape, labels[0].shape)\n",
    "\n",
    "    outputs = []\n",
    "    for batch_input, batch_label in zip(inputs, labels):            \n",
    "        output_batch = predict(eval_xs=batch_input, eval_ys=batch_label, softmax_temperature=softmax_temperature, return_logits=return_logits, eval_position=eval_position, model=model, num_classes=num_classes)\n",
    "           \n",
    "        outputs.append(output_batch)\n",
    "    \n",
    "    return torch.cat(outputs, 1).squeeze(1)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_features': 100,\n",
       " 'rescale_features': True,\n",
       " 'normalize_to_ranking': False,\n",
       " 'normalize_with_sqrt': False}"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_params_from_config(classifier.c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "950"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "569"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel(\n",
       "  (transformer_encoder): TransformerEncoderDiffInit(\n",
       "    (layers): ModuleList(\n",
       "      (0-11): 12 x TransformerEncoderLayer(\n",
       "        (self_attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (linear1): Linear(in_features=512, out_features=1024, bias=True)\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (linear2): Linear(in_features=1024, out_features=512, bias=True)\n",
       "        (norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (dropout1): Dropout(p=0.0, inplace=False)\n",
       "        (dropout2): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): Linear(in_features=100, out_features=512, bias=True)\n",
       "  (y_encoder): Linear(in_features=1, out_features=512, bias=True)\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=1024, bias=True)\n",
       "    (1): GELU(approximate='none')\n",
       "    (2): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\arik_\\AppData\\Local\\Temp\\ipykernel_207700\\865882981.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  softmax_temperature = torch.tensor(softmax_temperature).to(device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([569, 1, 30]) torch.Size([381, 1])\n",
      "torch.Size([569, 1, 30]) torch.Size([381, 1])\n",
      "torch.Size([569, 1, 100]) torch.Size([381, 1])\n"
     ]
    }
   ],
   "source": [
    "pred_custom = transformer_predict_custom(classifier.model[2], X_full, y_full, eval_pos,\n",
    "                                         device=classifier.device,\n",
    "                                         style=classifier.style,\n",
    "                                         preprocess_transform='power_all',\n",
    "                                         normalize_with_test=False,\n",
    "                                         softmax_temperature=classifier.temperature,\n",
    "                                         seed=classifier.seed,\n",
    "                                         return_logits=False,\n",
    "                                         batch_size_inference=classifier.batch_size_inference,\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "188"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pred_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1139e-01, 8.8861e-01],\n",
       "        [9.9998e-01, 1.5099e-05],\n",
       "        [9.9999e-01, 1.4381e-05],\n",
       "        [8.2190e-06, 9.9999e-01],\n",
       "        [2.5166e-06, 1.0000e+00],\n",
       "        [9.9999e-01, 1.0031e-05],\n",
       "        [9.9999e-01, 7.8525e-06],\n",
       "        [9.2876e-01, 7.1236e-02],\n",
       "        [1.1724e-01, 8.8276e-01],\n",
       "        [3.9087e-05, 9.9996e-01],\n",
       "        [5.1093e-02, 9.4891e-01],\n",
       "        [9.9852e-01, 1.4848e-03],\n",
       "        [1.2111e-04, 9.9988e-01],\n",
       "        [9.9227e-01, 7.7311e-03],\n",
       "        [3.2559e-04, 9.9967e-01],\n",
       "        [9.9467e-01, 5.3276e-03],\n",
       "        [8.9337e-06, 9.9999e-01],\n",
       "        [3.2585e-06, 1.0000e+00],\n",
       "        [5.7493e-05, 9.9994e-01],\n",
       "        [1.0000e+00, 3.8525e-06],\n",
       "        [5.0348e-02, 9.4965e-01],\n",
       "        [2.1155e-04, 9.9979e-01],\n",
       "        [1.0000e+00, 2.4908e-06],\n",
       "        [1.4606e-04, 9.9985e-01],\n",
       "        [1.2914e-05, 9.9999e-01],\n",
       "        [1.6486e-03, 9.9835e-01],\n",
       "        [2.5991e-06, 1.0000e+00],\n",
       "        [1.4376e-04, 9.9986e-01],\n",
       "        [4.7790e-06, 1.0000e+00],\n",
       "        [9.9999e-01, 9.7007e-06],\n",
       "        [1.0341e-04, 9.9990e-01],\n",
       "        [1.4062e-06, 1.0000e+00],\n",
       "        [2.1850e-03, 9.9782e-01],\n",
       "        [9.6777e-03, 9.9032e-01],\n",
       "        [2.0542e-06, 1.0000e+00],\n",
       "        [8.9067e-04, 9.9911e-01],\n",
       "        [9.8060e-01, 1.9403e-02],\n",
       "        [1.0542e-02, 9.8946e-01],\n",
       "        [1.0000e+00, 3.4323e-06],\n",
       "        [1.4300e-03, 9.9857e-01],\n",
       "        [1.4856e-06, 1.0000e+00],\n",
       "        [9.9998e-01, 1.7713e-05],\n",
       "        [3.1502e-05, 9.9997e-01],\n",
       "        [1.7649e-06, 1.0000e+00],\n",
       "        [1.9800e-01, 8.0200e-01],\n",
       "        [4.4902e-02, 9.5510e-01],\n",
       "        [1.8632e-05, 9.9998e-01],\n",
       "        [4.3076e-04, 9.9957e-01],\n",
       "        [1.2329e-02, 9.8767e-01],\n",
       "        [1.1761e-05, 9.9999e-01],\n",
       "        [9.9999e-01, 6.5749e-06],\n",
       "        [1.0000e+00, 2.8080e-06],\n",
       "        [2.3222e-01, 7.6778e-01],\n",
       "        [9.5333e-02, 9.0467e-01],\n",
       "        [2.2728e-05, 9.9998e-01],\n",
       "        [1.7778e-03, 9.9822e-01],\n",
       "        [3.8775e-06, 1.0000e+00],\n",
       "        [9.9996e-01, 3.9810e-05],\n",
       "        [9.8789e-01, 1.2107e-02],\n",
       "        [1.3077e-06, 1.0000e+00],\n",
       "        [1.0187e-05, 9.9999e-01],\n",
       "        [1.0000e+00, 1.8877e-06],\n",
       "        [9.9999e-01, 9.5760e-06],\n",
       "        [1.0829e-02, 9.8917e-01],\n",
       "        [6.5862e-06, 9.9999e-01],\n",
       "        [2.0168e-02, 9.7983e-01],\n",
       "        [1.0000e+00, 3.6049e-06],\n",
       "        [9.9998e-01, 2.0020e-05],\n",
       "        [9.9230e-05, 9.9990e-01],\n",
       "        [1.9958e-03, 9.9800e-01],\n",
       "        [9.9986e-01, 1.4128e-04],\n",
       "        [9.9987e-01, 1.3043e-04],\n",
       "        [4.5258e-05, 9.9995e-01],\n",
       "        [9.9997e-01, 2.8822e-05],\n",
       "        [1.3671e-03, 9.9863e-01],\n",
       "        [2.9411e-04, 9.9971e-01],\n",
       "        [5.5555e-04, 9.9944e-01],\n",
       "        [7.1497e-01, 2.8503e-01],\n",
       "        [1.5147e-06, 1.0000e+00],\n",
       "        [1.6819e-03, 9.9832e-01],\n",
       "        [9.9994e-01, 6.1149e-05],\n",
       "        [2.6250e-06, 1.0000e+00],\n",
       "        [9.5591e-01, 4.4091e-02],\n",
       "        [1.0000e+00, 2.5762e-06],\n",
       "        [9.9980e-01, 1.9538e-04],\n",
       "        [9.9995e-01, 5.1818e-05],\n",
       "        [9.9994e-01, 6.4503e-05],\n",
       "        [9.9923e-01, 7.6814e-04],\n",
       "        [6.1161e-05, 9.9994e-01],\n",
       "        [1.8635e-04, 9.9981e-01],\n",
       "        [6.1437e-05, 9.9994e-01],\n",
       "        [5.3467e-01, 4.6533e-01],\n",
       "        [1.8215e-01, 8.1785e-01],\n",
       "        [9.3025e-04, 9.9907e-01],\n",
       "        [2.8770e-05, 9.9997e-01],\n",
       "        [2.3044e-06, 1.0000e+00],\n",
       "        [9.9999e-01, 9.0245e-06],\n",
       "        [9.9998e-01, 1.5569e-05],\n",
       "        [1.2694e-06, 1.0000e+00],\n",
       "        [9.9983e-01, 1.6780e-04],\n",
       "        [9.9984e-01, 1.6370e-04],\n",
       "        [2.0329e-05, 9.9998e-01],\n",
       "        [9.9979e-01, 2.0696e-04],\n",
       "        [9.9999e-01, 7.9863e-06],\n",
       "        [5.4394e-04, 9.9946e-01],\n",
       "        [3.0912e-02, 9.6909e-01],\n",
       "        [2.9296e-05, 9.9997e-01],\n",
       "        [9.9998e-01, 1.6021e-05],\n",
       "        [4.7907e-03, 9.9521e-01],\n",
       "        [2.2542e-03, 9.9775e-01],\n",
       "        [9.9992e-01, 7.5738e-05],\n",
       "        [1.0443e-05, 9.9999e-01],\n",
       "        [3.9089e-01, 6.0911e-01],\n",
       "        [9.9997e-01, 2.5523e-05],\n",
       "        [3.7735e-02, 9.6227e-01],\n",
       "        [9.9999e-01, 1.2120e-05],\n",
       "        [1.1113e-05, 9.9999e-01],\n",
       "        [1.1114e-02, 9.8889e-01],\n",
       "        [9.3203e-04, 9.9907e-01],\n",
       "        [9.9999e-01, 7.8647e-06],\n",
       "        [3.2607e-02, 9.6739e-01],\n",
       "        [5.8633e-06, 9.9999e-01],\n",
       "        [3.8175e-05, 9.9996e-01],\n",
       "        [9.9999e-01, 1.3062e-05],\n",
       "        [1.1879e-03, 9.9881e-01],\n",
       "        [9.9999e-01, 8.8857e-06],\n",
       "        [9.9999e-01, 6.7347e-06],\n",
       "        [6.6924e-05, 9.9993e-01],\n",
       "        [5.5622e-06, 9.9999e-01],\n",
       "        [9.9999e-01, 6.8139e-06],\n",
       "        [9.9974e-01, 2.6391e-04],\n",
       "        [9.9998e-01, 2.3120e-05],\n",
       "        [1.4727e-03, 9.9853e-01],\n",
       "        [3.3138e-05, 9.9997e-01],\n",
       "        [4.1033e-03, 9.9590e-01],\n",
       "        [9.9895e-01, 1.0458e-03],\n",
       "        [2.2469e-01, 7.7531e-01],\n",
       "        [1.3276e-02, 9.8672e-01],\n",
       "        [1.9553e-01, 8.0447e-01],\n",
       "        [9.9998e-01, 2.1754e-05],\n",
       "        [4.6294e-04, 9.9954e-01],\n",
       "        [1.0000e+00, 4.7395e-06],\n",
       "        [1.1779e-06, 1.0000e+00],\n",
       "        [1.6115e-06, 1.0000e+00],\n",
       "        [9.9999e-01, 1.4895e-05],\n",
       "        [8.2570e-06, 9.9999e-01],\n",
       "        [1.0000e+00, 3.9278e-06],\n",
       "        [9.9995e-01, 4.8201e-05],\n",
       "        [9.8324e-01, 1.6756e-02],\n",
       "        [2.2991e-04, 9.9977e-01],\n",
       "        [9.9988e-01, 1.2281e-04],\n",
       "        [3.2431e-05, 9.9997e-01],\n",
       "        [2.8429e-06, 1.0000e+00],\n",
       "        [1.6939e-04, 9.9983e-01],\n",
       "        [1.7149e-04, 9.9983e-01],\n",
       "        [9.9999e-01, 1.3207e-05],\n",
       "        [9.9999e-01, 7.6634e-06],\n",
       "        [2.5168e-03, 9.9748e-01],\n",
       "        [2.2191e-05, 9.9998e-01],\n",
       "        [2.0037e-06, 1.0000e+00],\n",
       "        [5.8386e-03, 9.9416e-01],\n",
       "        [1.2716e-05, 9.9999e-01],\n",
       "        [4.5327e-05, 9.9995e-01],\n",
       "        [3.9230e-05, 9.9996e-01],\n",
       "        [9.8805e-01, 1.1951e-02],\n",
       "        [2.1489e-06, 1.0000e+00],\n",
       "        [8.2538e-05, 9.9992e-01],\n",
       "        [4.4212e-01, 5.5788e-01],\n",
       "        [3.9314e-05, 9.9996e-01],\n",
       "        [9.9987e-01, 1.3148e-04],\n",
       "        [1.4230e-03, 9.9858e-01],\n",
       "        [8.8478e-06, 9.9999e-01],\n",
       "        [3.4869e-05, 9.9997e-01],\n",
       "        [4.3057e-02, 9.5694e-01],\n",
       "        [4.6756e-06, 1.0000e+00],\n",
       "        [5.9890e-04, 9.9940e-01],\n",
       "        [9.4249e-01, 5.7513e-02],\n",
       "        [4.0541e-04, 9.9959e-01],\n",
       "        [4.7733e-05, 9.9995e-01],\n",
       "        [3.0788e-03, 9.9692e-01],\n",
       "        [4.9952e-03, 9.9500e-01],\n",
       "        [6.7063e-02, 9.3294e-01],\n",
       "        [4.7041e-05, 9.9995e-01],\n",
       "        [9.9805e-01, 1.9543e-03],\n",
       "        [9.9993e-01, 7.1009e-05],\n",
       "        [9.9699e-01, 3.0076e-03],\n",
       "        [7.2818e-01, 2.7182e-01],\n",
       "        [4.5883e-03, 9.9541e-01]], grad_fn=<SqueezeBackward1>)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_label_c = torch.argmax(pred_custom, dim=1).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "          True,  True,  True,  True,  True,  True,  True,  True]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_label_c == pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[2.5643e-02, 9.7436e-01],\n",
       "         [1.0000e+00, 1.4656e-06],\n",
       "         [9.9999e-01, 9.1454e-06],\n",
       "         [3.2564e-06, 1.0000e+00],\n",
       "         [3.4475e-06, 1.0000e+00],\n",
       "         [1.0000e+00, 4.6052e-06],\n",
       "         [1.0000e+00, 1.2244e-06],\n",
       "         [9.7865e-01, 2.1351e-02],\n",
       "         [4.8726e-01, 5.1274e-01],\n",
       "         [3.3818e-05, 9.9997e-01],\n",
       "         [1.9664e-02, 9.8034e-01],\n",
       "         [9.9965e-01, 3.5022e-04],\n",
       "         [2.5653e-05, 9.9997e-01],\n",
       "         [8.6371e-01, 1.3629e-01],\n",
       "         [2.1190e-04, 9.9979e-01],\n",
       "         [9.7162e-01, 2.8376e-02],\n",
       "         [3.6410e-06, 1.0000e+00],\n",
       "         [6.0988e-06, 9.9999e-01],\n",
       "         [6.8569e-05, 9.9993e-01],\n",
       "         [1.0000e+00, 6.5333e-07],\n",
       "         [1.5332e-02, 9.8467e-01],\n",
       "         [6.0217e-05, 9.9994e-01],\n",
       "         [1.0000e+00, 5.6474e-07],\n",
       "         [5.0694e-05, 9.9995e-01],\n",
       "         [1.6663e-05, 9.9998e-01],\n",
       "         [6.7215e-04, 9.9933e-01],\n",
       "         [4.2186e-06, 1.0000e+00],\n",
       "         [3.5856e-04, 9.9964e-01],\n",
       "         [3.7867e-06, 1.0000e+00],\n",
       "         [9.9998e-01, 1.8496e-05],\n",
       "         [2.1360e-05, 9.9998e-01],\n",
       "         [1.7655e-06, 1.0000e+00],\n",
       "         [6.7223e-03, 9.9328e-01],\n",
       "         [6.4960e-04, 9.9935e-01],\n",
       "         [2.0264e-06, 1.0000e+00],\n",
       "         [7.8577e-05, 9.9992e-01],\n",
       "         [9.9327e-01, 6.7303e-03],\n",
       "         [4.2090e-02, 9.5791e-01],\n",
       "         [1.0000e+00, 3.7241e-07],\n",
       "         [3.8462e-04, 9.9962e-01],\n",
       "         [2.4914e-06, 1.0000e+00],\n",
       "         [9.9999e-01, 9.2342e-06],\n",
       "         [1.3984e-05, 9.9999e-01],\n",
       "         [2.8289e-06, 1.0000e+00],\n",
       "         [2.1065e-01, 7.8935e-01],\n",
       "         [1.2720e-01, 8.7280e-01],\n",
       "         [6.6638e-04, 9.9933e-01],\n",
       "         [3.1039e-04, 9.9969e-01],\n",
       "         [3.4691e-02, 9.6531e-01],\n",
       "         [5.6511e-05, 9.9994e-01],\n",
       "         [1.0000e+00, 6.7858e-07],\n",
       "         [1.0000e+00, 4.4492e-07],\n",
       "         [3.3623e-01, 6.6377e-01],\n",
       "         [2.6499e-01, 7.3501e-01],\n",
       "         [3.1500e-05, 9.9997e-01],\n",
       "         [1.5271e-03, 9.9847e-01],\n",
       "         [3.2195e-06, 1.0000e+00],\n",
       "         [9.9999e-01, 1.1530e-05],\n",
       "         [9.8888e-01, 1.1116e-02],\n",
       "         [1.2611e-06, 1.0000e+00],\n",
       "         [4.9965e-06, 9.9999e-01],\n",
       "         [1.0000e+00, 4.8378e-07],\n",
       "         [1.0000e+00, 2.0424e-06],\n",
       "         [1.1516e-02, 9.8848e-01],\n",
       "         [5.0489e-06, 9.9999e-01],\n",
       "         [7.7054e-02, 9.2295e-01],\n",
       "         [1.0000e+00, 7.2707e-07],\n",
       "         [9.9998e-01, 2.2446e-05],\n",
       "         [3.4157e-05, 9.9997e-01],\n",
       "         [1.2994e-03, 9.9870e-01],\n",
       "         [9.9977e-01, 2.3491e-04],\n",
       "         [9.9995e-01, 5.3922e-05],\n",
       "         [1.6129e-05, 9.9998e-01],\n",
       "         [9.9999e-01, 8.2606e-06],\n",
       "         [6.3169e-04, 9.9937e-01],\n",
       "         [1.2497e-04, 9.9988e-01],\n",
       "         [1.7578e-04, 9.9982e-01],\n",
       "         [4.4011e-01, 5.5989e-01],\n",
       "         [2.3937e-06, 1.0000e+00],\n",
       "         [4.7321e-03, 9.9527e-01],\n",
       "         [9.9990e-01, 1.0284e-04],\n",
       "         [3.4062e-06, 1.0000e+00],\n",
       "         [7.7436e-01, 2.2564e-01],\n",
       "         [1.0000e+00, 9.0586e-07],\n",
       "         [9.9973e-01, 2.7449e-04],\n",
       "         [9.9938e-01, 6.1630e-04],\n",
       "         [9.9942e-01, 5.8251e-04],\n",
       "         [9.9657e-01, 3.4312e-03],\n",
       "         [2.9573e-05, 9.9997e-01],\n",
       "         [1.5886e-04, 9.9984e-01],\n",
       "         [7.3478e-05, 9.9993e-01],\n",
       "         [6.4731e-01, 3.5269e-01],\n",
       "         [1.8622e-02, 9.8138e-01],\n",
       "         [3.0858e-03, 9.9691e-01],\n",
       "         [7.7170e-05, 9.9992e-01],\n",
       "         [6.5737e-06, 9.9999e-01],\n",
       "         [1.0000e+00, 4.4413e-06],\n",
       "         [1.0000e+00, 4.2180e-06],\n",
       "         [1.1941e-06, 1.0000e+00],\n",
       "         [9.9996e-01, 4.0393e-05],\n",
       "         [9.9998e-01, 1.7807e-05],\n",
       "         [8.3024e-06, 9.9999e-01],\n",
       "         [9.9987e-01, 1.3101e-04],\n",
       "         [1.0000e+00, 2.6007e-06],\n",
       "         [9.9547e-04, 9.9900e-01],\n",
       "         [2.3337e-01, 7.6663e-01],\n",
       "         [2.6119e-05, 9.9997e-01],\n",
       "         [1.0000e+00, 3.3902e-06],\n",
       "         [8.5876e-03, 9.9141e-01],\n",
       "         [6.3679e-04, 9.9936e-01],\n",
       "         [9.9995e-01, 4.7437e-05],\n",
       "         [6.4003e-06, 9.9999e-01],\n",
       "         [1.9221e-01, 8.0779e-01],\n",
       "         [9.9995e-01, 4.9855e-05],\n",
       "         [4.6542e-01, 5.3458e-01],\n",
       "         [9.9999e-01, 6.6607e-06],\n",
       "         [5.9007e-05, 9.9994e-01],\n",
       "         [3.9412e-02, 9.6059e-01],\n",
       "         [1.3562e-03, 9.9864e-01],\n",
       "         [1.0000e+00, 3.0355e-06],\n",
       "         [3.6065e-02, 9.6394e-01],\n",
       "         [8.8374e-06, 9.9999e-01],\n",
       "         [3.5467e-05, 9.9996e-01],\n",
       "         [1.0000e+00, 4.2341e-06],\n",
       "         [1.8821e-03, 9.9812e-01],\n",
       "         [1.0000e+00, 7.1273e-07],\n",
       "         [1.0000e+00, 9.6552e-07],\n",
       "         [2.3223e-04, 9.9977e-01],\n",
       "         [8.2061e-06, 9.9999e-01],\n",
       "         [1.0000e+00, 3.2864e-06],\n",
       "         [9.9999e-01, 1.4653e-05],\n",
       "         [9.9997e-01, 2.8366e-05],\n",
       "         [1.1044e-03, 9.9890e-01],\n",
       "         [2.2656e-05, 9.9998e-01],\n",
       "         [2.0366e-03, 9.9796e-01],\n",
       "         [9.9964e-01, 3.6478e-04],\n",
       "         [1.1672e-01, 8.8328e-01],\n",
       "         [6.6648e-03, 9.9334e-01],\n",
       "         [6.0678e-02, 9.3932e-01],\n",
       "         [1.0000e+00, 1.7520e-06],\n",
       "         [3.4164e-04, 9.9966e-01],\n",
       "         [1.0000e+00, 8.7829e-07],\n",
       "         [1.7455e-06, 1.0000e+00],\n",
       "         [2.7262e-06, 1.0000e+00],\n",
       "         [1.0000e+00, 2.1478e-06],\n",
       "         [5.1842e-06, 9.9999e-01],\n",
       "         [1.0000e+00, 6.0753e-07],\n",
       "         [1.0000e+00, 3.3492e-06],\n",
       "         [9.6341e-01, 3.6590e-02],\n",
       "         [1.3638e-05, 9.9999e-01],\n",
       "         [9.9995e-01, 5.3793e-05],\n",
       "         [1.3521e-05, 9.9999e-01],\n",
       "         [1.9380e-06, 1.0000e+00],\n",
       "         [5.2873e-05, 9.9995e-01],\n",
       "         [3.1356e-04, 9.9969e-01],\n",
       "         [1.0000e+00, 4.6261e-06],\n",
       "         [9.9999e-01, 7.1312e-06],\n",
       "         [1.1212e-03, 9.9888e-01],\n",
       "         [7.7070e-06, 9.9999e-01],\n",
       "         [1.3797e-06, 1.0000e+00],\n",
       "         [2.2990e-02, 9.7701e-01],\n",
       "         [5.7986e-05, 9.9994e-01],\n",
       "         [8.4575e-05, 9.9992e-01],\n",
       "         [7.0880e-05, 9.9993e-01],\n",
       "         [9.6467e-01, 3.5327e-02],\n",
       "         [2.6408e-06, 1.0000e+00],\n",
       "         [4.4384e-06, 1.0000e+00],\n",
       "         [2.1722e-01, 7.8278e-01],\n",
       "         [8.7274e-04, 9.9913e-01],\n",
       "         [9.9806e-01, 1.9416e-03],\n",
       "         [3.6003e-03, 9.9640e-01],\n",
       "         [7.8643e-06, 9.9999e-01],\n",
       "         [1.7867e-05, 9.9998e-01],\n",
       "         [1.7889e-02, 9.8211e-01],\n",
       "         [4.6047e-06, 1.0000e+00],\n",
       "         [1.2236e-04, 9.9988e-01],\n",
       "         [9.2472e-01, 7.5278e-02],\n",
       "         [2.9449e-04, 9.9971e-01],\n",
       "         [4.2528e-05, 9.9996e-01],\n",
       "         [2.3115e-04, 9.9977e-01],\n",
       "         [5.0502e-03, 9.9495e-01],\n",
       "         [4.0793e-01, 5.9207e-01],\n",
       "         [2.7661e-04, 9.9972e-01],\n",
       "         [9.9908e-01, 9.1622e-04],\n",
       "         [9.9998e-01, 2.2103e-05],\n",
       "         [9.7130e-01, 2.8704e-02],\n",
       "         [6.2819e-01, 3.7181e-01],\n",
       "         [1.7292e-03, 9.9827e-01]]])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
