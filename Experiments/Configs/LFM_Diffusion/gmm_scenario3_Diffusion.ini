[confic_created_on]
time = {'Thu Sep  5 18:42:28 2024'}

[name]
name = basic_config_gmm_diagonal_big_v3

[BASIC]
n = 25
p = 5
batch_size = 512
n_epochs = 150
n_samples_per_epoch = 500000
n_samples_to_generate_at_once = 250000
shuffle = False
save_path = /content/drive/MyDrive/PFN_Experiments/Training_RunsCFM/basic_config_gmm_diagonal_big_v3_15_11_2024
train_frac = 0.5
val_frac = 0.1
n_batches_per_epoch = 488

[DATA_GENERATION]
pprogram = gmm_diagonal
scheduler_behaviour = All_constant
generate_x_behaviour = uniform
pprogram_params = {'n': '25', 'p': '5', 'k': 3, 'batch_size': '1024', 'a1': 5.0, 'b1': 2.0, 'dirichlet_beta': 0.5, 'lambda1': 5.0}

[MODEL]
type = TransformerCNFConditionalDecoder
n_input_features_encoder = 5
n_input_features_decoder = 30
d_model_encoder = 512
d_model_decoder = 512
n_heads_encoder = 8
n_heads_decoder = 8
d_ff_encoder = 1024
d_ff_decoder = 1024
dropout_encoder = 0.1
dropout_decoder = 0.1
n_conditional_input_features = 1
n_condition_features = 512
n_layers_condition_embedding = 3
n_layers_encoder = 8
n_layers_decoder = 6
use_positional_encoding_encoder = True
use_positional_encoding_decoder = False
use_self_attention_decoder = False
output_dim = 30
d_final_processing = 512
n_final_layers = 3
dropout_final = 0.1
treat_z_as_sequence = False

[TRAINING]
loss_function = CFMLossDiffusionVP
epsilon_for_t = 1e-05
beta_min = 0.1
beta_max = 20.0
sigma_min = 0.0001
learning_rate = 1e-06
weight_decay = 1e-05
scheduler = OneCycleLR
scheduler_params = {'max_lr': 0.0005, 'epochs': '150', 'steps_per_epoch': 488, 'pct_start': 0.1, 'div_factor': 25.0, 'final_div_factor': 10000.0}
early_stopping_patience = 100000
max_grad_norm = 1.0

[EVALUATION]
n_samples_per_model = 1000
n_synthetic_cases = 50
real_world_eval = Basic1
n_evaluation_cases_real_world = All
do_full_evaluation = True
save_path_data_real_world_eval = /content/drive/MyDrive/PFN_Experiments/RealWorldEvaluationData/DatasetsOpenML/numerical_regression.pkl
real_world_benchmark_id = 336
real_world_preprocessor = gmm_preprocessor_multivariate
results_dict_to_data_for_model = results_dict_to_data_x_tuple
result_dict_to_data_for_comparison_models = results_dict_to_data_x_tuple
discrete_z = True
numpyro_hmc = True
multi_chain = True

[FULL_MODEL]
sample_name = beta
sample_shape = (30,)
n_samples = 1000
batch_size = 1024
solve_adjoint = True
atol = 1e-07
rtol = 1e-07