[confic_created_on]
time = {'Sat Aug 31 15:26:59 2024'}

[name]
name = test_config_v1

[BASIC]
n = 50
p = 5
batch_size = 8
n_epochs = 1
n_samples_per_epoch = 20
n_samples_to_generate_at_once = 1000
shuffle = False
save_path = C:\Users\arik_\Documents\Dokumente\Job_Clausthal\PFNs\Repository\PFNExperiments\Experiments\Runs\test_config_v1_Sat_Aug_31_15_26_59_2024
train_frac = 0.5
val_frac = 0.1
n_batches_per_epoch = 2

[DATA_GENERATION]
pprogram = ig
use_intercept = False
scheduler_behaviour = All_constant
generate_x_behaviour = TabPFNX_extended1
x_data_files = ['C:\\Users\\arik_\\Documents\\Dokumente\\Job_Clausthal\\PFNs\\Repository\\PFNExperiments\\LinearRegression\\GenerativeModels\\GenerateX_TabPFN\\Saved_Data\\X_tabpfn_n50_p5_1_000_000_v2.pt']
pprogram_params = {'a': 5.0, 'b': 2.0, 'tau': 1.0}

[MODEL]
type = TransformerCNFConditionalDecoder
n_input_features_encoder = 6
n_input_features_decoder = 5
d_model_encoder = 512
d_model_decoder = 512
n_heads_encoder = 8
n_heads_decoder = 8
d_ff_encoder = 1024
d_ff_decoder = 1024
dropout_encoder = 0.1
dropout_decoder = 0.1
n_conditional_input_features = 1
n_condition_features = 512
n_layers_condition_embedding = 3
n_layers_encoder = 8
n_layers_decoder = 6
use_positional_encoding_encoder = True
use_positional_encoding_decoder = False
use_self_attention_decoder = False
output_dim = 5
d_final_processing = 512
n_final_layers = 3
dropout_final = 0.1
treat_z_as_sequence = False

[TRAINING]
loss_function = CFMLossOT2
sigma_min = 0.0001
learning_rate = 1e-06
weight_decay = 1e-05
scheduler = OneCycleLR
scheduler_params = {'max_lr': 0.0005, 'epochs': '1', 'steps_per_epoch': 2, 'pct_start': 0.1, 'div_factor': 25.0, 'final_div_factor': 10000.0}
early_stopping_patience = 100000
max_grad_norm = 1.0

[EVALUATION]
n_samples_per_model = 200
n_synthetic_cases = 5
real_world_eval = Basic1
n_evaluation_cases_real_world = 3
do_full_evaluation = False
save_path_data_real_world_eval = C:\Users\arik_\Documents\Dokumente\Job_Clausthal\PFNs\Repository\PFNExperiments\Evaluation\RealWorldEvaluation\DatasetsOpenML2
real_world_benchmark_id = 336

[FULL_MODEL]
sample_name = beta
sample_shape = (5,)
n_samples = 200
batch_size = 8
solve_adjoint = True
atol = 0.001
rtol = 0.001

